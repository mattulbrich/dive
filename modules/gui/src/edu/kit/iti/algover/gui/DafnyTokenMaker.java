package edu.kit.iti.algover.gui;

import edu.kit.iti.algover.parser.DafnyLexer;
import org.antlr.runtime.ANTLRInputStream;
import org.antlr.runtime.BufferedTokenStream;
import org.fife.ui.rsyntaxtextarea.AbstractTokenMaker;
import org.fife.ui.rsyntaxtextarea.Token;
import org.fife.ui.rsyntaxtextarea.TokenMap;
import org.fife.ui.rsyntaxtextarea.TokenTypes;

import javax.swing.text.Segment;
import java.io.ByteArrayInputStream;
import java.io.CharArrayReader;
import java.io.InputStream;

/**
 * Class ANTLRTokenMaker wraps a lexer generated by ANTLR to conform to the requirements of
 * a lexer (TokenMaker) used by RSyntaxTextArea.<p>
 *
 *	Here's what's in an ANTLR token
 * <ul>
 * 	<li>		getText(): this is ONLY the chars in this token, as a String
 * 	<li>		getCharPositionInLine(): start of token in the original line
 *	<li>		getTokenIndex(): the sequence number of this token in the line, beginning with 0
 *	<li>		getTokenType(): the ANTLR lexer's token type constant
 *	<li>		getLine(): the line number where this token occurs; always 1 in this context because we are lexing one line at a time
 * </ul><p>
 *
 * A lexer class generated by ANTLR defines a symbolic constant (in Java, a public static final int) for each token type specified
 * by the grammar. We can reference those constants as, for example, DafnyLexer.RESERVED_WORD.<p>
 *
 * 	Here's what's needed to create an RSTA token using method addToken:<p>
 *
 *		addToken(char[] array, int start, int end, int tokenType, int startOffset)<p>
 *
 *		Parameters:
 * <ul>
 * 	<li>		array - the character array from which to get the text
 * 	<li>		start - start offset in segment of token
 * 	<li>		end - end offset in segment of token
 * 	<li>		tokenType - the token's type, as defined by RSTA; see interface TokenTypes
 * 	<li>		startOffset - the offset in the document at which this token occurs
 * </ul><p>
 *
 * The contents of this file is placed into the public domain as of February 27, 2012.<p>
 *
 * @version Feb 27, 2012
 * @author  Gary Ford (Plaid Flannel Software)
 */

public class DafnyTokenMaker
        extends AbstractTokenMaker
        implements TokenTypes
{

    /** the lexer generated by ANTLR */
    private DafnyLexer mANTLRLexer;

    /**
     * Nullary constructor required by TokenMakerFactory.
     */
    public DafnyTokenMaker()
    {
        //mANTLRLexer = new DafnyLexer();

    } // end constructor


    public int getLastTokenTypeOnLine ( Segment pSegment, int initialTokenType )
    {
        try
        {
            //CharArrayReader tReader =
              //      new CharArrayReader( pSegment.array, pSegment.offset, pSegment.count );
            InputStream tReader = new ByteArrayInputStream( new String(pSegment.array).getBytes() , pSegment.offset, pSegment.count);
            mANTLRLexer =
                    new DafnyLexer( new ANTLRInputStream(tReader) );

            BufferedTokenStream tTokenStream =
                    new BufferedTokenStream( mANTLRLexer );

            org.antlr.runtime.Token lastToken = null;

            boolean inComment = initialTokenType == COMMENT_MULTILINE;

            // retrieve and convert tokens one at a time; note that 
            // the stream returns the EOF token as the last token
            while ( true )
            {
                org.antlr.runtime.Token tToken = tTokenStream.LT(1);

                // System.out.println( 
                // 	tToken + " -> " + 
                // 	(tToken.getType() >= 0 ? DafnyLexer.tokenNames[tToken.getType()] : "-1") );

                if ( inComment &&
                        convertTokenType(tToken.getType()) == COMMENT_MULTILINE ) inComment = false;

                if ( tToken.getType() == org.antlr.runtime.Token.EOF )
                {
                    System.out.println( tToken + " " + lastToken + " " + initialTokenType + " " + inComment );

                    if ( inComment )
                    {
                        System.out.println( "returning comment" );
                        System.out.println( lastToken + " " + initialTokenType );
                        return COMMENT_MULTILINE;
                    }
                    else if ( lastToken != null && convertTokenType(lastToken.getType()) == COMMENT_MULTILINE )
                    {
                        System.out.println( "returning comment" );
                        System.out.println( lastToken + " " + initialTokenType );
                        return COMMENT_MULTILINE;
                    }
                    else
                    {
                        System.out.println( "returning null" );
                        return NULL;
                    }
                }

                lastToken = tToken;

                tTokenStream.consume();

            } // end while
        }
        catch (Exception ex)
        {
            ex.printStackTrace();
        }

        return NULL;
    }

    // ————————————————————————————————————————
    /**
     * Returns the first token in a linked list of tokens created by the lexer.
     * <p>
     *
     * This method expects to reuse an existing lexer of class DafnyLexer; that class is
     * created by running ANTLR on the DafnyLexer.g grammar. 
     * Note that this grammar does not make use of multiline comments or documentation
     * comments, so the initial token type parameter is unused.<p>
     *
     * This method is needed because of the difference in how ANTLR and JFlex lexers
     * return their results: ANTLR uses a token stream, while JFlex uses a token linked list.<p>
     *
     * @param pSegment
     * 		the Segment from which the tokens are to be extracted
     * @param initialTokenType
     * 		the token-scanning state in which to start the scan (used primarily for multiline comments)
     * @param pSegmentOffset
     * 		the offset in the whole document where the list of tokens starts
     * @return
     * 		the first token in the linked list of tokens extracted from the Segment
     */
    @Override
    public Token getTokenList (Segment pSegment, int initialTokenType, int pSegmentOffset )
    {
        try
        {
            // create a Reader for the characters in the given Segment

            CharArrayReader tReader1 =
                    new CharArrayReader( pSegment.array, pSegment.offset, pSegment.count );

            // give that Reader to the ANTLR lexer for processing
            InputStream tReader = new ByteArrayInputStream( new String(pSegment.array).getBytes() , pSegment.offset, pSegment.count);
            //InputStream tReader = new BufferedReader(tReader1.read( pSegment.array, pSegment.offset, pSegment.count ));
            mANTLRLexer = new DafnyLexer( new ANTLRInputStream(tReader) );

            // get the resulting token stream from the lexer
            BufferedTokenStream tTokenStream =
                    new BufferedTokenStream( mANTLRLexer );

            resetTokenList(); // so we can create a fresh token list

            org.antlr.runtime.Token lastToken = null;

            boolean inComment = initialTokenType == COMMENT_MULTILINE;

            // retrieve and convert tokens one at a time; note that 
            // the stream returns the EOF token as the last token
            while ( true )
            {
                org.antlr.runtime.Token tToken = tTokenStream.LT(1);

                if ( inComment && convertTokenType(tToken.getType()) == COMMENT_MULTILINE )
                    inComment = false;

                if ( tToken.getType() == org.antlr.runtime.Token.EOF )
                {
                    System.out.println( lastToken + " " + initialTokenType + " " + inComment );

                    if ( !inComment &&
                            (lastToken == null ||
                                    convertTokenType(lastToken.getType()) != COMMENT_MULTILINE) )
                    {
                        System.out.println( "adding null" );
                        addNullToken();
                    }

                    break;
                }

                lastToken = tToken;

                tTokenStream.consume();

                // convert the ANTLR token to a RSyntaxTextArea token and add it to the linked list
                int tRSTATokenStart = tToken.getCharPositionInLine() + pSegment.offset;
                int tRSTATokenEnd = tRSTATokenStart + tToken.getText().length() - 1;
                int tRSTATokenOffset = pSegmentOffset + tToken.getCharPositionInLine();

                addToken( pSegment.array, tRSTATokenStart, tRSTATokenEnd,
                        inComment ? COMMENT_MULTILINE : convertTokenType(tToken.getType()),
                        tRSTATokenOffset );

            } // end while

        } // end try

        catch (Exception ex)
        {
            // quick fix for testing purposes
            System.out.println("Exception in ANTLRTokenMaker.getTokenList() " + ex.getMessage());

        } // end catch

        // return first node in the linked list
        return firstToken; // firstToken is declared in the superclass

    } // end getTokenList()

    /**
     * This method is required, but it is not needed. Token types are sufficient to identify
     * which tokens will be "highlighted".
     */
    @Override
    public TokenMap getWordsToHighlight()
    {
        return wordsToHighlight; // wordsToHighlight is declared in the superclass

    } // end getWordsToHighlight()

    /**
     * Converts an ANTLR token type to an RSTA token type.<p>
     *
     * The demo grammar used for testing ANTLRTokenMaker defines only those DafnyLexer token types
     * referenced below, and the SyntaxScheme used by the RSTA defines representations
     * only for those RSTA token types referenced below.
     *
     * @param tokenTypeAntlr
     * 		the type code for an ANTLR token
     * @return
     * 		the type code for a corresponding RSTA token
     */
    private int convertTokenType ( int tokenTypeAntlr )
    {
        switch ( tokenTypeAntlr )
        {
            // case DafnyLexer.NullLiteral:
            // 	return NULL;
           // case DafnyLexer.Identifier:
            case DafnyLexer.T__75:
            case DafnyLexer.T__76:
                case DafnyLexer.T__77:
                return FUNCTION;
            case DafnyLexer.ELSE:
            case DafnyLexer.IF:
            case DafnyLexer.WHILE:
                return RESERVED_WORD;
            case DafnyLexer.BOOL:
            case DafnyLexer.ARRAY:
            case DafnyLexer.INT:
            case DafnyLexer.ARGS:
            case DafnyLexer.ASSERT:
            case DafnyLexer.ASSUME:
            case DafnyLexer.DECREASES:
            case DafnyLexer.RETURNS:

                return RESERVED_WORD_2;
            // case DafnyLexer.PROCESSING_API_VARIABLES:
            // 	return VARIABLE;
            // case DafnyLexer.PROCESSING_API_CONSTANTS:
            //	return REGEX;
            case DafnyLexer.WS:
                return WHITESPACE;
           // case DafnyLexer.HexColorLiteral:
           // case DafnyLexer.DecimalFloatingPointLiteral:
           // case DafnyLexer.FloatingPointLiteral:
           case DafnyLexer.INT_LIT:
            //case DafnyLexer.BooleanLiteral:
//            case DafnyLexer.ARRAY:
                return DATA_TYPE;
            case DafnyLexer.ID:
           // case DafnyLexer.CharacterLiteral:
                return LITERAL_STRING_DOUBLE_QUOTE;
            case DafnyLexer.SINGLELINE_COMMENT:
          //  case DafnyLexer.COMMENT:
                //case DafnyLexer.JavaMultilineComment:
                return COMMENT_MULTILINE;
           // case DafnyLexer.UnmatchedStringLiteral:
           // case DafnyLexer.UnmatchedCharacterLiteral:
                //case DafnyLexer.UnmatchedMultilineComment:
                // case DafnyLexer.UnmatchedMultilineCommentStart:
                // case DafnyLexer.UnmatchedMultilineCommentEnd:
               // return ERROR_STRING_DOUBLE;
            default:
                return PREPROCESSOR;
        }

        // if (tokenTypeAntlr == DafnyLexer.INVALID)
        // 	return ERROR_CHAR;

    } // end convertTokenType()

} // end class ANTLRTokenMaker